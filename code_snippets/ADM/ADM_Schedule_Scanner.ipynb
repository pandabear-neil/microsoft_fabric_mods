{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c66cb4-f427-4359-8023-dad0f511519f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Notes\n",
    "* Pure python implementation using Polars LazyFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b3b24-615b-45c3-bb64-7dc6cbf16e14",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce449d6-0007-4920-821b-41fb7f750628",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import sempy.fabric as fabric\n",
    "import notebookutils as nbutl\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "from typing import *\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a3055-a998-42d1-ba9d-d49bccb532ad",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd94aa-c3e7-4959-8f4b-203a7e371712",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# list of workspaces to be scanned, support both workspaceId(recommended) and workspaceName\n",
    "workspaceList = ['workspace1', 'workspace2']\n",
    "\n",
    "# Define Destination Delta Table path that stores Fabric Schedules Metadata\n",
    "destTablePath = 'abfss://{workspaceId}@onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/{schemaName}/{tableName}' # Replace with actual delta table path\n",
    "\n",
    "# Datetime Parameters\n",
    "timezone_LCL = 'Australia/Adelaide' # Replace with your local timezone, https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\n",
    "zUPD_UTC, zUPD_LCL = datetime.now(), datetime.now(pytz.timezone(timezone_LCL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bbfd1-1ce6-40c1-b656-ff5d99a27b6f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820ab7f-ab81-469f-9de7-d2801edcca62",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Define ItemKey dataclass structure\n",
    "@dataclass\n",
    "class ItemKey:\n",
    "    DefaultKey: str\n",
    "    ScheduleKey: str\n",
    "    UrlKey: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebf83d-e0fb-47c3-9085-797480d37dff",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Define items keys for REST API calls for supported item types\n",
    "ITEM_KEYS = [\n",
    "    ItemKey('DataPipeline', 'Pipeline', 'pipelines'),\n",
    "    ItemKey('CopyJob', 'CopyJob', 'copyjobs'),\n",
    "    ItemKey('Notebook', 'RunNotebook', 'synapsenotebooks'),\n",
    "    ItemKey('SparkJobDefinition', 'sparkjob', 'sparkjobdefinitions'),\n",
    "    ItemKey('Dataflow', 'Refresh', 'dataflows-gen2')   \n",
    "]\n",
    "\n",
    "# Convert ItemKeys to dictionary for quick lookup\n",
    "ITEM_KEY_LOOKUP = {item.DefaultKey: item for item in ITEM_KEYS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49d81e-0cba-4cbf-90ef-91317854f575",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e70a8-5761-4014-a1d4-5e25f5ace29a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------- Utilities -------------------- #\n",
    "def convert_ordinal(n: int) -> str:\n",
    "    \"\"\"Convert integer to its ordinal representation.\"\"\"\n",
    "    if 10 <= n % 100 <= 20:\n",
    "        suffix = 'th'\n",
    "    else:\n",
    "        suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(n % 10, 'th')\n",
    "    return f'{n}{suffix}'\n",
    "\n",
    "\n",
    "# -------------------- API Wrappers -------------------- #\n",
    "def get_workspace_items(client, workspace_id, item_key_lookup):\n",
    "    \"\"\"Fetch valid items from a workspace based on known types.\"\"\"\n",
    "    items = client.get(f'/v1/workspaces/{workspace_id}/items').json().get('value', [])\n",
    "    valid_types = set(item_key_lookup.keys())\n",
    "    return [i for i in items if i['type'] in valid_types]\n",
    "\n",
    "\n",
    "def get_item_schedules(client, workspace_id, item_id, schedule_key):\n",
    "    \"\"\"Fetch schedules for a given item.\"\"\"\n",
    "    try:\n",
    "        return client.get(f\"/v1/workspaces/{workspace_id}/items/{item_id}/jobs/{schedule_key}/schedules\").json().get('value', [])\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_last_run(client, workspace_id, item_id):\n",
    "    \"\"\"Fetch the most recent run for an item.\"\"\"\n",
    "    runs = client.get(f\"/v1/workspaces/{workspace_id}/items/{item_id}/jobs/instances\").json().get('value', [])\n",
    "    return max(runs, key=lambda r: r['startTimeUtc'], default={'startTimeUtc': None, 'endTimeUtc': None, 'status': 'N.A.'})\n",
    "\n",
    "\n",
    "# -------------------- Metadata Parser -------------------- #\n",
    "def parse_schedule_metadata(item, schedule, last_run, workspace_id, workspace_name, item_key):\n",
    "    \"\"\"Parse and format schedule metadata for reporting.\"\"\"\n",
    "    config = schedule['configuration']\n",
    "    schedule_type = config['type']\n",
    "\n",
    "    if schedule_type == 'Cron':\n",
    "        schedule_type = 'By Minutes'\n",
    "    elif schedule_type == 'Weekly':\n",
    "        schedule_type += ': ' + ', '.join(config['weekdays'])\n",
    "    elif schedule_type == 'Monthly':\n",
    "        schedule_type += f\": Every {config['recurrence']} month{'s' if config['recurrence'] > 1 else ''}\"\n",
    "        occ = config['occurrence']\n",
    "        if occ['occurrenceType'] == 'DayOfMonth':\n",
    "            schedule_type += f\" on the {convert_ordinal(occ['dayOfMonth'])} day\"\n",
    "        elif occ['occurrenceType'] == 'OrdinalWeekday':\n",
    "            schedule_type += f\" on the {occ['weekIndex']} {occ['weekday']}\"\n",
    "\n",
    "    scheduled_times = (\n",
    "        [f\"Every {config['interval']} Minutes\"]\n",
    "        if config['type'] == 'Cron'\n",
    "        else config['times']\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'ItemId': item['id'],\n",
    "        'ItemName': item['displayName'],\n",
    "        'ItemType': item['type'],\n",
    "        'ItemDescription': item['description'],\n",
    "        'ScheduleId': schedule['id'],\n",
    "        'ScheduleEnabled': schedule['enabled'],\n",
    "        'ScheduleType': schedule_type,\n",
    "        'ScheduledTimes': scheduled_times,\n",
    "        'ScheduleTimezone': config['localTimeZoneId'],\n",
    "        'LastRun_StartTime_UTC': last_run['startTimeUtc'],\n",
    "        'LastRun_EndTime_UTC': last_run['endTimeUtc'],\n",
    "        'LastRun_Status': last_run['status'],\n",
    "        'ScheduleCreatedTime_UTC': schedule['createdDateTime'],\n",
    "        'ScheduleStartTime_LCL': config['startDateTime'],\n",
    "        'ScheduleEndTime_LCL': config['endDateTime'],\n",
    "        'WorkspaceId': workspace_id,\n",
    "        'WorkspaceName': workspace_name,\n",
    "        'ItemURL': f\"https://app.powerbi.com/groups/{workspace_id}/{item_key.UrlKey}/{item['id']}?experience=power-bi\"\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------- Main Scanner -------------------- #\n",
    "def scan_item_schedule(workspace, item_key_lookup=ITEM_KEY_LOOKUP, update_time=zUPD_LCL, local_tz=timezone_LCL):\n",
    "    \"\"\"Scan schedules for all valid items in a workspace and return a Polars DataFrame.\"\"\"\n",
    "    client = fabric.FabricRestClient()\n",
    "    workspace_name, workspace_id = fabric.resolve_workspace_name_and_id(workspace)\n",
    "    items = get_workspace_items(client, workspace_id, item_key_lookup)\n",
    "\n",
    "    records = []\n",
    "    for item in items:\n",
    "        item_key = item_key_lookup[item['type']]\n",
    "        schedules = get_item_schedules(client, workspace_id, item['id'], item_key.ScheduleKey)\n",
    "        last_run = get_last_run(client, workspace_id, item['id'])\n",
    "\n",
    "        for schedule in schedules:\n",
    "            if schedule:\n",
    "                metadata = parse_schedule_metadata(item, schedule, last_run, workspace_id, workspace_name, item_key)\n",
    "                records.append(metadata)\n",
    "\n",
    "    df_lazy = pl.LazyFrame(records)\n",
    "\n",
    "    datetime_cols = [\n",
    "        'LastRun_StartTime_UTC', 'LastRun_EndTime_UTC',\n",
    "        'ScheduleCreatedTime_UTC', 'ScheduleStartTime_LCL', 'ScheduleEndTime_LCL'\n",
    "    ]\n",
    "\n",
    "    df_lazy = (\n",
    "        df_lazy.filter(pl.col('ScheduleEnabled') == True) # remove this filter if you wants to see disabled schedules as well\n",
    "          .with_columns([\n",
    "              pl.col(datetime_cols).cast(pl.Datetime, strict=False).dt.replace_time_zone('UTC'),\n",
    "              pl.when(pl.col('ScheduleType') == 'Cron')\n",
    "                .then(pl.col('ScheduledTimes').list.first())\n",
    "                .otherwise(pl.col('ScheduledTimes').list.join(', '))\n",
    "                .cast(pl.String, strict=False)\n",
    "                .alias('ScheduledTimes'),\n",
    "              pl.lit(update_time).dt.replace_time_zone('UTC').alias('zUPD')\n",
    "          ])\n",
    "          .with_columns([\n",
    "              pl.col('LastRun_StartTime_UTC').dt.convert_time_zone(local_tz).dt.replace_time_zone('UTC').alias('LastRun_StartTime_LCL'), # workaround to avoid TIMEZONE_NTZ error\n",
    "              pl.col('LastRun_EndTime_UTC').dt.convert_time_zone(local_tz).dt.replace_time_zone('UTC').alias('LastRun_EndTime_LCL'), # workaround to avoid TIMEZONE_NTZ error\n",
    "              pl.col('ScheduleCreatedTime_UTC').dt.convert_time_zone(local_tz).dt.replace_time_zone('UTC').alias('ScheduleCreatedTime_LCL') # workaround to avoid TIMEZONE_NTZ error\n",
    "          ])\n",
    "          .select([\n",
    "            'ItemId','ItemName','ItemType','ItemDescription',\n",
    "            'WorkspaceId','WorkspaceName',\n",
    "            'ScheduleEnabled','ScheduleId','ScheduleType',\n",
    "            'ScheduledTimes','ScheduleTimezone',\n",
    "            'LastRun_StartTime_LCL','LastRun_EndTime_LCL','LastRun_Status',\n",
    "            'ScheduleStartTime_LCL','ScheduleEndTime_LCL',\n",
    "            'ScheduleCreatedTime_LCL',\n",
    "            'ItemURL','zUPD'\n",
    "        ])\n",
    "        .sort(pl.col('LastRun_StartTime_LCL'), descending = True)\n",
    "    )\n",
    "\n",
    "    return df_lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c938b7d-fb5c-4b2d-94fd-337e264d6d7b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62e8b1-7392-4d2a-9669-89cf631f5868",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# concat workspace item schedules into one dataframe\n",
    "df_schedules = pl.concat([scan_item_schedule(w) for w in workspaceList], how = 'vertical').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f5dcb-c34f-4ed3-b2c8-67e341fc4b90",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb884d8-da43-4c3a-8b01-3457f3943f81",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# display(df_schedules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1f275-5eee-4df1-88ca-7ba3b9af6502",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4b881-5977-4a46-a43c-5e722ffe8971",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Write Fabric Schedules to a Delta Table\n",
    "df_schedules.write_delta(\n",
    "    destTablePath,\n",
    "    mode = 'overwrite',\n",
    "#    delta_write_options={'schema_mode': 'overwrite'}\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {},
   "lakehouse": {
    "default_lakehouse": "489e9064-0a57-49e0-aa8a-058c08642212",
    "default_lakehouse_name": "zR2_DataLake",
    "default_lakehouse_workspace_id": "cb2afc3e-0b20-4744-94a5-905247dc2699",
    "known_lakehouses": [
     {
      "id": "489e9064-0a57-49e0-aa8a-058c08642212"
     },
     {
      "id": "ccf68fe5-d045-467b-8f42-b2ea374b9ff3"
     }
    ]
   },
   "warehouse": {}
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
